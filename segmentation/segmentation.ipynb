{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in seg_real-1 to png-mask-semantic: 100% [11666662 / 11666662] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to seg_real-1 in png-mask-semantic:: 100%|██████████| 366/366 [00:00<00:00, 7261.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"bwISTK3XdVI7LVTIYM62\")\n",
    "project = rf.workspace(\"zwdyolov5\").project(\"seg_real\")\n",
    "dataset = project.version(1).download(\"png-mask-semantic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # 忽略警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def transfer_label(label):\n",
    "    width, height, channel = label.shape\n",
    "    res = np.zeros_like(label)\n",
    "    channel = label[:, :, 0]\n",
    "    for row_idx in range(height):\n",
    "        for col_idx in range(width):\n",
    "            color = channel[row_idx, col_idx]\n",
    "            channel_map = {0 : 0, 1 : 1, 2 : 2}\n",
    "            res[row_idx, col_idx, channel_map[channel[row_idx, col_idx]]] = 1\n",
    "    return res\n",
    "\n",
    "def transfer_label_2class(label):\n",
    "    width, height, _ = label.shape\n",
    "    channel = label[:, :, 0]\n",
    "    res = np.zeros((640, 640, 1))\n",
    "    \n",
    "    for row_idx in range(height):\n",
    "        for col_idx in range(width):\n",
    "            if channel[row_idx, col_idx] == 1:\n",
    "                res[row_idx, col_idx, 0] = 1 \n",
    "                \n",
    "    return res\n",
    "            \n",
    "def load_image(type):\n",
    "    root = f\"./seg_real-1/{type}\"\n",
    "    mask_image_list = []\n",
    "    origin_image_list = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            mask_file_path = os.path.join(root, file)\n",
    "            if mask_file_path[-3:] == \"png\":\n",
    "                mask_frame = cv2.imread(mask_file_path)\n",
    "                mask_frame_rgb = mask_frame[:, :, ::-1].copy()\n",
    "                mask_frame_label = transfer_label_2class(mask_frame_rgb)\n",
    "                mask_image_list.append(mask_frame_label)\n",
    "                \n",
    "                origin_file_path = mask_file_path[:-9] + \".jpg\"\n",
    "                origin_frame = cv2.imread(origin_file_path)\n",
    "                origin_frame_rgb = origin_frame[:, :, ::-1].copy()\n",
    "                origin_image_list.append(origin_frame_rgb)\n",
    "                \n",
    "    mask_image_np = np.vstack(mask_image_list).reshape((-1, 640, 640, 1))\n",
    "    origin_image_np = np.vstack(origin_image_list).reshape((-1, 640, 640, 3))\n",
    "    \n",
    "    images, labels = shuffle(origin_image_np, mask_image_np)\n",
    "    print(f'images.shape: {images.shape}')\n",
    "    print(f'labels.shape: {labels.shape}')\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "images.shape: (167, 640, 640, 3)\n",
      "labels.shape: (167, 640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "images.shape: (6, 640, 640, 3)\n",
      "labels.shape: (6, 640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "(640, 640, 1)\n",
      "images.shape: (6, 640, 640, 3)\n",
      "labels.shape: (6, 640, 640, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_image('train')\n",
    "test_images, test_labels = load_image('test')\n",
    "val_images, val_labels = load_image('valid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary items from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, pool_size):\n",
    "    # 创建网络模型\n",
    "    model = Sequential()\n",
    "    # 对输入层进行归一化处理\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    # 卷积层1，名为Conv1\n",
    "    model.add(Conv2D(4, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # 卷积层2\n",
    "    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # 最大化层\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # 卷积层3\n",
    "    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 卷积层4\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 卷积层5\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 最大化层2\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    # 上采样层 2\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # 反卷积层 3\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 反卷积层 4\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 反卷积层 5\n",
    "    model.add(Conv2DTranspose(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 上采样层 3\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # 反卷积层 6\n",
    "    model.add(Conv2DTranspose(4, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "    # 输出层\n",
    "    model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'sigmoid', name = 'Final'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_6 (Bat  (None, 640, 640, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 638, 638, 4)       112       \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 636, 636, 8)       296       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 318, 318, 8)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 316, 316, 8)       584       \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 316, 316, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 314, 314, 16)      1168      \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 314, 314, 16)      0         \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 312, 312, 16)      2320      \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 312, 312, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 156, 156, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " up_sampling2d_18 (UpSampli  (None, 312, 312, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " Deconv3 (Conv2DTranspose)   (None, 314, 314, 16)      2320      \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 314, 314, 16)      0         \n",
      "                                                                 \n",
      " Deconv4 (Conv2DTranspose)   (None, 316, 316, 16)      2320      \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 316, 316, 16)      0         \n",
      "                                                                 \n",
      " Deconv5 (Conv2DTranspose)   (None, 318, 318, 8)       1160      \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 318, 318, 8)       0         \n",
      "                                                                 \n",
      " up_sampling2d_19 (UpSampli  (None, 636, 636, 8)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " Deconv6 (Conv2DTranspose)   (None, 638, 638, 4)       292       \n",
      "                                                                 \n",
      " Final (Conv2DTranspose)     (None, 640, 640, 1)       37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10621 (41.49 KB)\n",
      "Trainable params: 10615 (41.46 KB)\n",
      "Non-trainable params: 6 (24.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pool_size = (2, 2)\n",
    "input_shape = train_images.shape[1:]\n",
    "model = create_model(input_shape, pool_size)\n",
    "\n",
    "# datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "# datagen.fit(images)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "# 可视化模型\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.0575 - val_loss: 0.0481\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0333 - val_loss: 0.0517\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.0273 - val_loss: 0.0398\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0250 - val_loss: 0.0454\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0242 - val_loss: 0.0532\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0236 - val_loss: 0.0327\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.0227 - val_loss: 0.0349\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.0224 - val_loss: 0.0271\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0221 - val_loss: 0.0248\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0216 - val_loss: 0.0255\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0210 - val_loss: 0.0281\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0198 - val_loss: 0.0218\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0187 - val_loss: 0.0178\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0184 - val_loss: 0.0173\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0185 - val_loss: 0.0206\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.0182 - val_loss: 0.0154\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.0179 - val_loss: 0.0170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dbf43130>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "model.fit(train_images, train_labels, batch_size=30, epochs=epochs, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('latest_try2.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def create_video(path, model):\n",
    "    vs = cv2.VideoCapture(path)\n",
    "    while True:\n",
    "        (grabbed, frame_source) = vs.read()\n",
    "        if not grabbed: break\n",
    "        \n",
    "        height, width = frame_source.shape[:2]\n",
    "        \n",
    "        frame = cv2.resize(frame_source ,(640, 640))\n",
    "        \n",
    "        # 为frame_input添加一个维度\n",
    "        frame_input = frame[None, :, :, :]\n",
    "        prediction = model.predict(frame_input)\n",
    "        prediction = prediction[0] * 255\n",
    "        \n",
    "        blank = cv2.resize(prediction, (width, height))\n",
    "        output = cv2.addWeighted(frame_source, 0.3, blank, 0.7, 0, dtype = cv2.CV_32F)\n",
    "        print(output)\n",
    "        \n",
    "        # 清空绘图空间\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # 显示处理结果\n",
    "        _, jpg = cv2.imencode('.jpg', output)\n",
    "        display(jpg)\n",
    "\n",
    "        #按键盘中的q键退出检测\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):   break\n",
    "        \n",
    "    # 释放资源\n",
    "    print(\"[INFO] cleaning up...\")\n",
    "    vs.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m create_video(\u001b[39m'\u001b[39m\u001b[39m../pose/test.mp4\u001b[39m\u001b[39m'\u001b[39m, model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "def deal_with_video(video_path, model_path):\n",
    "    save_dir = \"./seg_video/\"\n",
    "    # if os.path.exists(save_dir):\n",
    "    #     import shutil\n",
    "    #     shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    # os.mkdir(save_dir)\n",
    "    save_path = f\"{save_dir}/seg_video.mp4\"\n",
    "    \n",
    "    source = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    fps = source.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(source.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(source.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = source.read()\n",
    "        if ret == False:    break\n",
    "        \n",
    "        frame_resize = cv2.resize(frame, (640, 640))\n",
    "        prediction = model.predict(frame_resize[None, :, :, :])[0]\n",
    "        \n",
    "        blank = np.zeros((640, 640, 3))\n",
    "        blank[:, :, 1] = prediction[:, :, 0]\n",
    "        blank = blank * 255\n",
    "        \n",
    "        blank = cv2.resize(blank, (w, h))\n",
    "        new_frame = cv2.addWeighted(frame, 0.3, blank, 0.7, 0, dtype = cv2.CV_8U)\n",
    "        output = cv2.resize(new_frame, (w, h))\n",
    "                \n",
    "        vid_writer.write(output)\n",
    "    \n",
    "    # for idx, (frame, frame_rgb) in enumerate(source):\n",
    "    #     vid_writer.write(frame)\n",
    "        \n",
    "deal_with_video('../pose/test.mp4', './latest_try2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "model = load_model('second_try.h5')\n",
    "\n",
    "frame_source = cv2.imread('./road-segmenttation-6/test/IMG_6089_jpg.rf.7bc033675cb0a80f24f8a91aae978a64.jpg')\n",
    "height, width = frame_source.shape[:2]\n",
    "frame = cv2.resize(frame_source ,(640, 640))\n",
    "# 为frame_input添加一个维度\n",
    "frame_input = frame[None, :, :, :]\n",
    "prediction = model.predict(frame_input)\n",
    "prediction = prediction[0] * 255\n",
    "\n",
    "\n",
    "blank = cv2.resize(prediction, (width, height))\n",
    "output = cv2.addWeighted(frame_source, 0, blank, 1, 0, dtype = cv2.CV_32F)\n",
    "\n",
    "cv2.imwrite('test.png', output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "model = load_model('first_try.h5')\n",
    "for root, dirs, files in os.walk('./seg_real-1/train'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if file_path[-3:] == \"jpg\":\n",
    "            frame_source = cv2.imread(file_path)\n",
    "            height, width = frame_source.shape[:2]\n",
    "            frame = cv2.resize(frame_source ,(640, 640))\n",
    "            # 为frame_input添加一个维度\n",
    "            frame_input = frame[None, :, :, :]\n",
    "            prediction = model.predict(frame_input)\n",
    "            prediction = prediction[0] * 255\n",
    "\n",
    "            blank = cv2.resize(prediction, (width, height))\n",
    "            output = cv2.addWeighted(frame_source, 0.3, blank, 0.7, 0, dtype = cv2.CV_32F)\n",
    "            cv2.imwrite(f'./generate/{file}', output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "frame = cv2.imread('./road-segmenttation-6/train/1_jpg.rf.1f002cde2f7e14e6d12e6d8ea7fbfe5f.jpg')\n",
    "model = load_model('third_try.h5')\n",
    "\n",
    "frame = cv2.resize(frame ,(640, 640))\n",
    "# 为frame_input添加一个维度\n",
    "frame_input = frame[None, :, :, :]\n",
    "            \n",
    "predict = model.predict(frame_input)\n",
    "\n",
    "flatten = predict.reshape(-1)\n",
    "set(flatten.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = cv2.imread('./seg_real-1/train/1686399388294716_mp4-0_jpg.rf.367e373d2e7f550d020f112b5bb4f96a_mask.png')\n",
    "test = label[:,:,0].reshape(-1)\n",
    "set(test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_labels[:, :, :, :].reshape(-1)\n",
    "set(test.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_blank(image , label):\n",
    "    blank = np.zeros((640, 640, 3))\n",
    "    blank[:, :, 0] = label[:, :, 0]\n",
    "    blank = blank * 255\n",
    "    cv2.imwrite('./generate/1.jpg', blank)\n",
    "    \n",
    "    cv2.imwrite('./generate/1ori.jpg', image)\n",
    "\n",
    "label = train_labels[0]\n",
    "image = train_images[0]\n",
    "show_blank(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 8s 1s/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('latest_try2.h5')\n",
    "prediction = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = prediction[0]\n",
    "image = train_images[0]\n",
    "show_blank(image, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a66a995458df657f2d1dd1215d3fd21014c75477484430839b4fdbbf23622b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
